{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb39219",
   "metadata": {
    "papermill": {
     "duration": 0.004199,
     "end_time": "2025-01-12T23:04:33.984314",
     "exception": false,
     "start_time": "2025-01-12T23:04:33.980115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de187fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T23:04:33.993024Z",
     "iopub.status.busy": "2025-01-12T23:04:33.992624Z",
     "iopub.status.idle": "2025-01-12T23:04:51.704284Z",
     "shell.execute_reply": "2025-01-12T23:04:51.703608Z"
    },
    "papermill": {
     "duration": 17.717942,
     "end_time": "2025-01-12T23:04:51.706046",
     "exception": false,
     "start_time": "2025-01-12T23:04:33.988104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('pip install --force-reinstall /kaggle/input/janestreet2025-code/janestreet-0.1-py3-none-any.whl')\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch \n",
    "\n",
    "from kaggle_evaluation import jane_street_inference_server\n",
    "\n",
    "from janestreet.pipeline import FullPipeline, PipelineCV\n",
    "from janestreet.data_processor import DataProcessor\n",
    "from janestreet.config import PATH_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cec9d1",
   "metadata": {
    "papermill": {
     "duration": 0.002354,
     "end_time": "2025-01-12T23:04:51.711232",
     "exception": false,
     "start_time": "2025-01-12T23:04:51.708878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a2e1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T23:04:51.717018Z",
     "iopub.status.busy": "2025-01-12T23:04:51.716765Z",
     "iopub.status.idle": "2025-01-12T23:04:51.722325Z",
     "shell.execute_reply": "2025-01-12T23:04:51.721342Z"
    },
    "papermill": {
     "duration": 0.009996,
     "end_time": "2025-01-12T23:04:51.723697",
     "exception": false,
     "start_time": "2025-01-12T23:04:51.713701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_2.0_700_gru_2.1_700_gru_2.2_700_gru_3.0_700_gru_3.1_700_gru_3.2_700\n",
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"full\"\n",
    "MODEL_NAMES = [\"gru_2.0_700\", \"gru_2.1_700\", \"gru_2.2_700\", \"gru_3.0_700\", \"gru_3.1_700\", \"gru_3.2_700\"]\n",
    "WEIGHTS = np.array([1.0]*len(MODEL_NAMES))/ len(MODEL_NAMES)\n",
    "WEIGHTS = WEIGHTS/sum(WEIGHTS)\n",
    "N_ROLL = 1000\n",
    "\n",
    "print(\"_\".join(MODEL_NAMES))\n",
    "print(WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbee7eb",
   "metadata": {
    "papermill": {
     "duration": 0.00225,
     "end_time": "2025-01-12T23:04:51.728408",
     "exception": false,
     "start_time": "2025-01-12T23:04:51.726158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51154e78",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-12T23:04:51.734122Z",
     "iopub.status.busy": "2025-01-12T23:04:51.733894Z",
     "iopub.status.idle": "2025-01-12T23:04:57.507410Z",
     "shell.execute_reply": "2025-01-12T23:04:57.506390Z"
    },
    "papermill": {
     "duration": 5.778255,
     "end_time": "2025-01-12T23:04:57.509178",
     "exception": false,
     "start_time": "2025-01-12T23:04:51.730923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.0_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 0}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.1_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 1}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_2.2_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [500], 'dropout_rates': [0.3, 0.0, 0.0], 'hidden_sizes_linear': [500, 300], 'dropout_rates_linear': [0.2, 0.1], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 2}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.0_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 0}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.1_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 1}\n",
      "Number of features: 125\n",
      "4\n",
      "WARNING: Preprocessor not found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gru_3.2_700\n",
      "{'model_type': 'gru', 'hidden_sizes': [250, 150, 150], 'dropout_rates': [0.0, 0.0, 0.0], 'hidden_sizes_linear': [], 'dropout_rates_linear': [], 'lr': 0.0005, 'batch_size': 1, 'epochs': 8, 'early_stopping_patience': 1, 'early_stopping': False, 'lr_patience': 10, 'lr_factor': 0.5, 'lr_refit': 0.0003, 'random_seed': 2}\n",
      "Number of features: 125\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor(MODEL_NAMES[0]).load()\n",
    "\n",
    "pipelines = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    pipeline = FullPipeline(\n",
    "        None,\n",
    "        run_name=RUN_NAME,\n",
    "        name=model_name,\n",
    "        load_model=True,\n",
    "        features=None,\n",
    "        save_to_disc=False\n",
    "    )\n",
    "    pipeline.fit(verbose=True)\n",
    "    pipelines[model_name] = pipeline\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(model_name)\n",
    "    print(pipeline.model.get_params())\n",
    "    print(f\"Number of features: {len(pipeline.features)}\")\n",
    "    print(pipeline.model.model.num_resp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021a098",
   "metadata": {
    "papermill": {
     "duration": 0.002733,
     "end_time": "2025-01-12T23:04:57.515147",
     "exception": false,
     "start_time": "2025-01-12T23:04:57.512414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load tail of train data for rolling features calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be25083a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T23:04:57.521882Z",
     "iopub.status.busy": "2025-01-12T23:04:57.521565Z",
     "iopub.status.idle": "2025-01-12T23:04:59.244937Z",
     "shell.execute_reply": "2025-01-12T23:04:59.244133Z"
    },
    "papermill": {
     "duration": 1.728541,
     "end_time": "2025-01-12T23:04:59.246573",
     "exception": false,
     "start_time": "2025-01-12T23:04:57.518032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_DATE = 1698\n",
    "COLS_ID = ['row_id', 'date_id', 'time_id', 'symbol_id', 'weight', 'is_scored']\n",
    "\n",
    "df_raw = pl.scan_parquet(f\"{PATH_DATA}/train.parquet\")\n",
    "df_raw = df_raw.filter(pl.col(\"date_id\")>=MAX_DATE-10)\n",
    "df_raw = df_raw.collect()\n",
    "df_raw = df_raw.with_columns(\n",
    "    pl.lit(-1).cast(pl.Int64).alias(\"row_id\"),\n",
    "    pl.lit(True).alias(\"is_scored\"),\n",
    "    (pl.col(\"date_id\")-MAX_DATE-1).alias(\"date_id\")\n",
    ")\n",
    "df_raw = df_raw.select(COLS_ID + data_processor.COLS_FEATURES_INIT)\n",
    "\n",
    "df_raw = (\n",
    "    df_raw.filter(pl.col(\"date_id\") >= -5)\n",
    "    .sort(['date_id', 'time_id', 'symbol_id'])\n",
    ")\n",
    "\n",
    "hidden_states = [None] * len(pipelines)\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db2986",
   "metadata": {
    "papermill": {
     "duration": 0.002833,
     "end_time": "2025-01-12T23:04:59.252612",
     "exception": false,
     "start_time": "2025-01-12T23:04:59.249779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655a4d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T23:04:59.259264Z",
     "iopub.status.busy": "2025-01-12T23:04:59.259019Z",
     "iopub.status.idle": "2025-01-12T23:05:00.556430Z",
     "shell.execute_reply": "2025-01-12T23:05:00.554989Z"
    },
    "papermill": {
     "duration": 1.302437,
     "end_time": "2025-01-12T23:05:00.557928",
     "exception": false,
     "start_time": "2025-01-12T23:04:59.255491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1139: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (39, 2)\n",
      "┌────────┬─────────────┐\n",
      "│ row_id ┆ responder_6 │\n",
      "│ ---    ┆ ---         │\n",
      "│ i64    ┆ f64         │\n",
      "╞════════╪═════════════╡\n",
      "│ 0      ┆ 0.006225    │\n",
      "│ 1      ┆ 0.001164    │\n",
      "│ 2      ┆ -0.015933   │\n",
      "│ 3      ┆ -0.013856   │\n",
      "│ 4      ┆ 0.028691    │\n",
      "│ …      ┆ …           │\n",
      "│ 34     ┆ -0.011823   │\n",
      "│ 35     ┆ -0.003499   │\n",
      "│ 36     ┆ -0.005554   │\n",
      "│ 37     ┆ -0.004253   │\n",
      "│ 38     ┆ -0.014129   │\n",
      "└────────┴─────────────┘\n",
      "(0, 1.0164384841918945)\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "CNT_DATES = 9\n",
    "CNT_DATES_NOT_SCORED = 4\n",
    "\n",
    "time_start = time.time()\n",
    "time_start_not_scored = time.time()\n",
    "time_est = 0\n",
    "time_est_not_scored = 0\n",
    "cnt_dates = 0\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global df_raw\n",
    "    global hidden_states\n",
    "    global pipeline\n",
    "    global dfs\n",
    "    global time_est, time_start, time_start_not_scored, time_est_not_scored\n",
    "    global cnt_dates\n",
    "    \n",
    "    date_id = test[\"date_id\"][0]\n",
    "    time_id = test[\"time_id\"][0]\n",
    "    is_scored = test[\"is_scored\"][0]\n",
    "\n",
    "    # Count time for debug\n",
    "    if DEBUG:\n",
    "        if not is_scored:\n",
    "            time_est_not_scored = time.time()-time_start_not_scored\n",
    "        else:\n",
    "            time_est = time.time()-time_start\n",
    "\n",
    "        if time_id == 0:\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            if date_id == 1:\n",
    "                time_start_not_scored = time.time()\n",
    "    \n",
    "            if date_id == CNT_DATES_NOT_SCORED: \n",
    "                time_start = time.time()\n",
    "\n",
    "    # Reset hidden states and collect data for weights update\n",
    "    if time_id == 0:\n",
    "        cnt_dates += 1\n",
    "        hidden_states = [None for _, p in pipelines.items()]\n",
    "        lags = lags.with_columns(\n",
    "            pl.col(\"responder_6_lag_1\").alias(\"responder_6\"),\n",
    "            pl.lit(date_id-1).cast(pl.Int16).alias(\"date_id\")\n",
    "        ).select([\"date_id\", \"time_id\", \"symbol_id\", \"responder_6\"])\n",
    "        if cnt_dates > 1:\n",
    "            df = pl.concat(dfs)\n",
    "            dfs = []\n",
    "            df = df.join(lags, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "            df = df.sort([\"date_id\", \"time_id\", \"symbol_id\"])\n",
    "\n",
    "    # Add data to raw dataframe\n",
    "    test = test.select(df_raw.columns)\n",
    "    df_raw = pl.concat([df_raw, test], how=\"vertical_relaxed\")\n",
    "    df_raw = df_raw.select(test.columns)\n",
    "    \n",
    "    # Cut raw data (keep last N_ROLL time_ids for each symbol)\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .group_by([\"symbol_id\"])\n",
    "        .tail(N_ROLL)\n",
    "    )\n",
    "\n",
    "    # Calculate features and save\n",
    "    df_cur = data_processor.process_test_data(df_raw, fast=True, date_id=date_id, time_id=time_id, symbols=test[\"symbol_id\"])\n",
    "    df_cur = df_cur.sort([\"symbol_id\"])\n",
    "    dfs.append(df_cur)\n",
    "    df_cur = df_cur.with_columns(pl.lit(None).alias(\"responder_6\"))\n",
    "    \n",
    "    # Update model weights\n",
    "    if (time_id == 0) & (cnt_dates > 1):\n",
    "        if len(df) > 968:\n",
    "            for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "                pipeline.update(df)\n",
    "\n",
    "    # Make predictions\n",
    "    if is_scored:\n",
    "        preds = []\n",
    "        for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "            pred, hidden_states[i] = pipeline.predict(df_cur, hidden=hidden_states[i], n_times=1)\n",
    "            preds.append(pred)\n",
    "        pred = np.average(preds, axis=0, weights=WEIGHTS)\n",
    "    \n",
    "        df_cur = df_cur.with_columns(pl.Series(\"responder_6\", pred))\n",
    "        df_cur = test.select([\"date_id\", \"time_id\", \"symbol_id\"]).join(df_cur, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "        predictions = df_cur.select([\"row_id\", \"responder_6\"])\n",
    "    else:\n",
    "        predictions = test.select(\n",
    "            'row_id',\n",
    "            pl.lit(0.0).alias('responder_6'),\n",
    "        )\n",
    "\n",
    "    if DEBUG:\n",
    "        if time_id % 100 == 0:\n",
    "            n_nans = sum(sum(predictions.fill_nan(None).null_count().to_numpy()))\n",
    "            print(\n",
    "                f\"{date_id} {time_id:3.0f} (is_scored {is_scored}): \"\n",
    "                f\"time elps {time.time()-start_time:.4f}, # nans {n_nans}\"\n",
    "            )\n",
    "    else:\n",
    "        if (time_id==0)&(date_id==0):\n",
    "            print(predictions)\n",
    "            print((time_id, time.time()-start_time))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    \n",
    "inference_server = jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    if not DEBUG:\n",
    "        inference_server.run_local_gateway(\n",
    "            (\n",
    "                f'{PATH_DATA}/test.parquet',\n",
    "                f'{PATH_DATA}/lags.parquet',\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            (\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_test.parquet',\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_lag.parquet',\n",
    "            )\n",
    "        )\n",
    "\n",
    "if DEBUG:\n",
    "    time_est_cur = time_est/(CNT_DATES-CNT_DATES_NOT_SCORED)*200/60/60\n",
    "    time_est_scored = time_est/(CNT_DATES-CNT_DATES_NOT_SCORED)*120/60/60\n",
    "    time_est_not_scored = time_est_not_scored/(CNT_DATES_NOT_SCORED-1)*240/60/60\n",
    "    time_est_final = time_est_scored + time_est_not_scored\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Estimated current time: {time_est_cur:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=True): {time_est_scored:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=False): {time_est_not_scored:.4f}\")\n",
    "    print(f\"Estimated final time: {time_est_final:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b360d08",
   "metadata": {
    "papermill": {
     "duration": 0.002928,
     "end_time": "2025-01-12T23:05:00.564186",
     "exception": false,
     "start_time": "2025-01-12T23:05:00.561258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb2a46",
   "metadata": {
    "papermill": {
     "duration": 0.002894,
     "end_time": "2025-01-12T23:05:00.570260",
     "exception": false,
     "start_time": "2025-01-12T23:05:00.567366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6468154,
     "sourceId": 10454258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6468162,
     "sourceId": 10454272,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 215844687,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.337374,
   "end_time": "2025-01-12T23:05:03.060096",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-12T23:04:30.722722",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
